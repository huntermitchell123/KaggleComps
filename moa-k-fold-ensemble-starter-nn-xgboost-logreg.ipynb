{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nHunter Mitchell\n09/16/20\nMechanisms of Action (MoA) Kaggle Competition\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Intro"},{"metadata":{},"cell_type":"markdown","source":"This kernel serves as a stratified k-fold ensemble approach baseline for the MoA (Mechanisms of Action) kaggle competition. The 3 models I have seen mostly used for this competition are Neural Networks, XGBoost (or some other boosted tree model), and Logistic Regression. Here I present a simple starter notebook to ensemble these three models with cross validation."},{"metadata":{},"cell_type":"markdown","source":"There are many ways to improve the validation and leaderboard score from this notebook. Here are some ideas to experiment with:\n* Principal Component Analysis\n* Grid search to optimize model hyperparameters\n* Experimenting with number of epochs, number of layers, types of layers, learning rate, etc. for Neural Network\n* Bagging/boosting with other models"},{"metadata":{},"cell_type":"markdown","source":"## Getting everything ready"},{"metadata":{},"cell_type":"markdown","source":"We will be using a multi-label stratified K-fold. Scikit-learn doesn't support this, but there is one located in this GitHub repository: [https://github.com/trent-b/iterative-stratification](http://) . We would normally be able to install this package with a simple pip command, but the competition rules state no internet use is allowed. Therefore, we will have to manually add this to our input."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"### Importing necessary libraries\n\nimport sys\nsys.path.append('/kaggle/input/iterativestratification') # Multilabel Stratified K-Fold package\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import log_loss\n\nimport time\n\nimport category_encoders as ce\n\n%matplotlib inline\n\nimport matplotlib\nimport matplotlib.pyplot as plt","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Settings\n\nSEED = 2020 \nFOLDS = 4\nEPOCHS = 25\nBATCH_SIZE = 128\n\n\n# Which models to use\ninclude_xgboost = True\ninclude_neural_net = True\ninclude_logreg = False\n\n\nlr_start=0.0001\nlr_max=0.0003\nlr_min=0.00001\nlr_rampup_epochs=5\nlr_sustain_epochs=2\nlr_exp_decay=.7","execution_count":89,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"### Creating dataframes\n\nTEST_FEATURES_PATH = \"/kaggle/input/lish-moa/test_features.csv\"\nTRAIN_FEATURES_PATH = \"/kaggle/input/lish-moa/train_features.csv\"\nTRAIN_TARGETS_PATH = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\nTRAIN_TARGETS_NONSCORED_PATH = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\nSAMPLE_SUB_PATH = \"/kaggle/input/lish-moa/sample_submission.csv\"\n\ntest_features_df = pd.read_csv(TEST_FEATURES_PATH).sort_values(by='sig_id')\ntrain_features_df = pd.read_csv(TRAIN_FEATURES_PATH).sort_values(by='sig_id')\ntrain_targets_df = pd.read_csv(TRAIN_TARGETS_PATH).sort_values(by='sig_id')\ntrain_targets_nonscored_df = pd.read_csv(TRAIN_TARGETS_NONSCORED_PATH)\nsample_sub_df = pd.read_csv(SAMPLE_SUB_PATH).sort_values(by='sig_id')","execution_count":90,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding our data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Features\n#print(train_features_df.head()) \n#print(train_features_df.describe())\n\n\n### Labels\n#print(train_targets_df.head())\n#print(train_targets_df.describe())\n\n\n### Submission\n#print(sample_sub_df.head())","execution_count":91,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are using 875 features to predict binary labels on 206 different classes. We have 23,814 instances to train on, and each instance can be multiple different classes. This makes this a multi-label classification problem."},{"metadata":{},"cell_type":"markdown","source":"It is always a good idea to look at the distribution of positive vs negative labels in each class. This helps us know how to split our training data better, and know what to look for in results."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Check how many positive labels are in each class\n\nvalue_counts_arr = np.sort([train_targets_df[col].value_counts()[1] for col in train_targets_df.columns])\n\nprint(value_counts_arr)","execution_count":92,"outputs":[{"output_type":"stream","text":"[  1   1   1   6   6   6   6   6   6   6   6   6   6   6   6   6   6   6\n   6   7   7   7   7  12  12  12  12  12  12  12  12  12  12  12  13  13\n  17  18  18  18  18  18  18  18  18  18  18  18  18  18  19  19  19  19\n  23  23  24  24  24  24  24  25  25  25  25  25  25  25  25  26  26  26\n  29  30  30  30  30  30  30  31  31  31  31  32  35  36  36  36  36  36\n  36  36  36  36  36  36  36  37  37  37  37  37  37  38  39  42  42  42\n  42  43  44  47  48  48  48  48  48  48  48  49  50  51  54  54  54  55\n  55  56  56  59  60  60  60  61  61  61  62  62  66  67  67  68  71  72\n  72  72  73  73  73  73  73  74  74  80  80  84  85  89  89  92  93  96\n  96  96  97  98 102 103 104 106 106 115 115 119 121 127 130 151 158 165\n 170 190 192 223 236 241 264 266 267 270 273 279 281 283 297 301 316 336\n 340 360 367 402 404 424 435 726 832]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Plot histogram of 1s counts in classes \n\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\n\nplt.hist(value_counts_arr, 50, facecolor='g', alpha=0.75)\nplt.xlabel('Number of 1\\'s')\nplt.ylabel('Number of classes')\nplt.title('Value Counts of 1\\'s in classes')\nplt.show()","execution_count":93,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"As you can see, there is a significantly small amount of positive labels in many classes. Three classes only have one positive instance! We must make sure we have these instances in the training set and not the validation set, or else our model will only predict one class! This is why we have to use a stratified k-fold."},{"metadata":{},"cell_type":"markdown","source":"## Preparing our data"},{"metadata":{},"cell_type":"markdown","source":"I decided to use One-Hot encoding for the categorical features. There are several other encoders to try that may perform better.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"### Dealing w/ categorical features\n\n\n# Encode training categorical features\nenc1 = ce.OneHotEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(train_features_df)\ntrain_features_enc_df = enc1.transform(train_features_df)\n\n# Encode testing categorical features\nenc2 = ce.OneHotEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(test_features_df)\ntest_features_enc_df = enc2.transform(test_features_df)","execution_count":117,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Verify\n\n#print(train_features_enc_df.head())\n#print(train_features_enc_df.describe())\n\n#print(test_features_enc_df.head())\n#print(test_features_enc_df.describe())","execution_count":118,"outputs":[{"output_type":"stream","text":"         sig_id  cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  \\\n0  id_000644bb2          1          0          1          0          0   \n1  id_000779bfc          1          0          0          1          0   \n2  id_000a6266a          1          0          0          0          1   \n3  id_0015fd391          1          0          0          0          1   \n4  id_001626bd3          1          0          0          1          0   \n\n   cp_dose_1  cp_dose_2     g-0     g-1  ...    c-90    c-91    c-92    c-93  \\\n0          1          0  1.0620  0.5577  ...  0.2862  0.2584  0.8076  0.5523   \n1          1          0  0.0743  0.4087  ... -0.4265  0.7543  0.4708  0.0230   \n2          1          0  0.6280  0.5817  ... -0.7250 -0.6297  0.6103  0.0223   \n3          1          0 -0.5138 -0.2491  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4          0          1 -0.3254 -0.4009  ...  0.0042  0.0048  0.6670  1.0690   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n0 -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n1  0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n2 -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n3 -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n\n[5 rows x 880 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Initialize stratified k-fold object\n\nskf = MultilabelStratifiedKFold(n_splits = FOLDS,random_state=SEED,shuffle=True)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Rename dataframes and drop 'id' columns\n\nX = train_features_enc_df.drop(columns=['sig_id'])\nX_test = test_features_enc_df.drop(columns=['sig_id'])\ny = train_targets_df.drop(columns=['sig_id'])","execution_count":119,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble setup"},{"metadata":{},"cell_type":"markdown","source":"My neural network contains 3 hidden layers, with batch normalization and dropout. This architecture is very simple (trains in only a few seconds w/ GPU) and should be experimented with to see what works best. Be sure to keep the last layer's activation as 'sigmoid' so that the outputs are all in [0,1]."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tf_model():\n    model = tf.keras.Sequential([\n        L.Flatten(input_shape=(1,879)),\n        L.Dense(2000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(206, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    model.summary()\n    \n    return model","execution_count":98,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This type of learning rate schedule has become the go-to for Kaggle competitions. It starts out small, ramps up to a certain threshold for a couple epochs, then decays exponentially."},{"metadata":{"trusted":true},"cell_type":"code","source":"### learning rate schedule\n\ndef lrfn(epoch):\n    \n    if epoch < lr_rampup_epochs:\n        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n        lr = lr_max\n    else:\n        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n    return lr","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_lr():\n    rng = [i for i in range(EPOCHS)]\n    y = [lrfn(x) for x in rng]\n    plt.plot(rng, y)\n    print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Fit model\n\ndef fit_model(model,X_train,X_valid,y_train,y_valid):\n\n    start = time.time()\n    \n    print('Beginning to fit ',type(model))\n\n    if 'tensorflow' in str(type(model)): # Fit neural net model\n    \n        model.fit(\n            X_train,\n            y_train,\n            epochs=EPOCHS,\n            verbose=1,\n            batch_size=BATCH_SIZE,\n            callbacks=[lr_schedule],\n            validation_data=(X_valid,y_valid)\n        )\n    \n    else: # Fit other type of model\n    \n        model.fit(X_train,y_train)\n\n    print('Total time taken to fit model: ', time.time() - start, ' seconds')","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Make Predictions\n\ndef get_preds(model,X_valid,final=False):\n\n    if 'tensorflow' in str(type(model)): # Neural Network model predictions \n        \n        if final==True:\n            preds = np.array(model.predict(X_test).astype(\"float64\"))\n        else:\n            preds = np.array(model.predict(X_valid).astype(\"float64\"))\n            \n    else:    # Other model predictions          \n        \n        if final==True:\n            preds = np.array(model.predict_proba(X_test))\n        else:\n            preds = np.array(model.predict_proba(X_valid))\n        \n        preds = preds[:,:,1].T\n    \n    return preds","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Calculate validation score\n\ndef calc_loss(vals,preds):\n\n    score = log_loss(np.ravel(vals),np.ravel(preds))\n    \n    cv_scores.append(score)\n\n    print('Validation log loss score: {}'.format(score))","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_model(model,X_train,X_valid,y_train,y_valid):\n\n    ### fit the model\n    fit_model(model,X_train,X_valid,y_train,y_valid)\n\n    print('Getting validation predictions...')\n    \n    ### get the predictions\n    temp_val_preds = get_preds(model,X_valid,final=False)\n    \n    ### calculate log loss\n    calc_loss(y_valid,temp_val_preds)\n    \n    print('Calculating final predictions...')\n\n    ### final preds\n    final_preds.append(get_preds(model,X_valid,final=True))\n    \n    print('Done')","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### XGBoost Model\n\nif include_xgboost == True:\n    \n    model_1 = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\n    # The MultiOutputClassifier wrapper creates one model for each class (i.e. 206 different models total)\n\n    # Using parameters from https://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification\n    params = {'estimator__colsample_bytree': 0.6522,\n          'estimator__gamma': 3.6975,\n          'estimator__learning_rate': 0.0503,\n          'estimator__max_delta_step': 2.0706,\n          'estimator__max_depth': 10,\n          'estimator__min_child_weight': 31.5800,\n          'estimator__n_estimators': 166,\n          'estimator__subsample': 0.8639\n         }\n\n    model_1.set_params(**params)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Neural Network Model\n\nif include_neural_net == True:\n    \n    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n    \n    plot_lr()\n    \n    model_2 = get_tf_model()","execution_count":120,"outputs":[{"output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_3 (Flatten)          (None, 879)               0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 2000)              1760000   \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 2000)              8000      \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 2000)              0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 1000)              2001000   \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 1000)              4000      \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 1000)              0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 1000)              1001000   \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 1000)              4000      \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 1000)              0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 206)               206206    \n=================================================================\nTotal params: 4,984,206\nTrainable params: 4,976,206\nNon-trainable params: 8,000\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Logistic Regression model\n\nif include_logreg == True:\n    \n    model_3 = MultiOutputClassifier(LogisticRegression(max_iter=10000, tol=0.1, C = 0.5,verbose=0,random_state = SEED))","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train models"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfinal_preds = []","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Stratified K-Fold loop \n\nfor fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n    \n    print('Beginning fold',fold+1)\n    print(\"TRAIN INDEX:\", train_index, \"VALID INDEX:\", valid_index)\n    \n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    if include_xgboost == True:\n        \n        run_model(model_1,X_train,X_valid,y_train,y_valid) # takes ~4 minutes\n        \n    if include_neural_net == True:\n        \n        run_model(model_2,X_train,X_valid,y_train,y_valid) # takes ~10 seconds with GPU\n        \n    if include_logreg == True:\n        \n        run_model(model_3,X_train,X_valid,y_train,y_valid) # takes ~8 min\n        \n","execution_count":122,"outputs":[{"output_type":"stream","text":"Beginning fold 1\nTRAIN INDEX: [    0     2     3 ... 23811 23812 23813] VALID INDEX: [    1     5     8 ... 23803 23809 23810]\nX_train    cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n0          1          0          1          0          0          1   \n2          1          0          0          0          1          1   \n3          1          0          0          0          1          1   \n4          1          0          0          1          0          0   \n6          1          0          1          0          0          0   \n\n   cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n0          0  1.0620  0.5577 -0.2479  ...  0.2862  0.2584  0.8076  0.5523   \n2          0  0.6280  0.5817  1.5540  ... -0.7250 -0.6297  0.6103  0.0223   \n3          0 -0.5138 -0.2491 -0.2656  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4          1 -0.3254 -0.4009  0.9700  ...  0.0042  0.0048  0.6670  1.0690   \n6          1  2.0440  1.7000 -1.5390  ...  0.1855  1.1720  0.8325  0.6486   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n0 -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n2 -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n3 -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n6  0.8090  1.5880  2.4670  0.0357  0.1351 -0.3179  \n\n[5 rows x 879 columns] \n\n\n\ny_train    5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n0                            0                       0               0   \n2                            0                       0               0   \n3                            0                       0               0   \n4                            0                       0               0   \n6                            0                       0               0   \n\n   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n0                               0                                  0   \n2                               0                                  0   \n3                               0                                  0   \n4                               0                                  0   \n6                               0                                  0   \n\n   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n0                               0                           0   \n2                               0                           0   \n3                               0                           0   \n4                               0                           0   \n6                               0                           0   \n\n   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n0                              0                           0   \n2                              0                           0   \n3                              0                           0   \n4                              0                           0   \n6                              0                           0   \n\n   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                            0  ...                                      0   \n2                            0  ...                                      0   \n3                            0  ...                                      0   \n4                            0  ...                                      0   \n6                            0  ...                                      0   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0             0                0                  0   \n2             0                0                  0   \n3             0                0                  0   \n4             0                0                  0   \n6             0                0                  0   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                          0                                      0   \n2                          0                                      0   \n3                          0                                      0   \n4                          0                                      0   \n6                          0                                      0   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0                0          0                           0              0  \n2                0          0                           0              0  \n3                0          0                           0              0  \n4                0          0                           0              0  \n6                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nX_valid     cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n1           1          0          0          1          0          1   \n5           1          0          1          0          0          1   \n8           1          0          0          0          1          1   \n9           1          0          0          0          1          0   \n16          1          0          0          0          1          1   \n\n    cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n1           0  0.0743  0.4087  0.2991  ... -0.4265  0.7543  0.4708  0.0230   \n5           0 -0.6111  0.2941 -0.9901  ...  1.8390  1.1570 -1.0120  1.9010   \n8           0 -0.3014  0.5545 -0.2576  ... -1.6470  0.2863  1.1070 -0.7735   \n9           1 -0.0630  0.2564 -0.5279  ...  0.2201  0.5601 -0.3501 -1.4070   \n16          0  8.7380  0.1914  2.4380  ... -9.9840 -9.9840 -9.9840 -9.9840   \n\n      c-94    c-95    c-96    c-97    c-98    c-99  \n1   0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n5   1.4270  0.4519  1.2120  0.3765  0.7848  1.3990  \n8  -1.0280 -1.3070 -0.1167 -0.1241 -0.6420  0.5543  \n9  -0.1717 -1.1160 -0.8745 -0.2716  0.0189 -2.0000  \n16 -9.9840 -9.9840 -9.9840 -9.9840 -9.9840 -6.7840  \n\n[5 rows x 879 columns] \n\n\n\ny_valid     5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n1                             0                       0               0   \n5                             0                       0               0   \n8                             0                       0               0   \n9                             0                       0               0   \n16                            0                       0               0   \n\n    acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n1                                0                                  0   \n5                                0                                  0   \n8                                0                                  0   \n9                                0                                  0   \n16                               0                                  0   \n\n    acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n1                                0                           0   \n5                                0                           0   \n8                                0                           0   \n9                                0                           0   \n16                               0                           0   \n\n    adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n1                               0                           0   \n5                               0                           0   \n8                               0                           0   \n9                               0                           0   \n16                              0                           0   \n\n    adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n1                             0  ...                                      0   \n5                             0  ...                                      0   \n8                             0  ...                                      0   \n9                             0  ...                                      0   \n16                            0  ...                                      0   \n\n    trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n1              0                0                  0   \n5              0                0                  0   \n8              0                0                  0   \n9              0                0                  0   \n16             0                0                  0   \n\n    tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n1                           0                                      0   \n5                           0                                      0   \n8                           0                                      0   \n9                           0                                      0   \n16                          0                                      0   \n\n    vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n1                 0          0                           0              0  \n5                 0          0                           0              0  \n8                 0          0                           0              0  \n9                 0          0                           0              0  \n16                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nBeginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\nLearning rate schedule: 0.0001 to 0.0003 to 1.4e-05\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\nEpoch 1/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.8338 - accuracy: 0.0084 - val_loss: 0.6692 - val_accuracy: 0.0131\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\nEpoch 2/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.6927 - accuracy: 0.0171 - val_loss: 0.5499 - val_accuracy: 0.0202\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\nEpoch 3/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.4503 - accuracy: 0.0219 - val_loss: 0.2571 - val_accuracy: 0.0220\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\nEpoch 4/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.1692 - accuracy: 0.0214 - val_loss: 0.0850 - val_accuracy: 0.0336\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\nEpoch 5/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0648 - accuracy: 0.0282 - val_loss: 0.0429 - val_accuracy: 0.0393\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 6/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0367 - accuracy: 0.0375 - val_loss: 0.0287 - val_accuracy: 0.0568\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 7/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.0283 - accuracy: 0.0498 - val_loss: 0.0242 - val_accuracy: 0.0453\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 8/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0245 - accuracy: 0.0535 - val_loss: 0.0219 - val_accuracy: 0.0838\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\nEpoch 9/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0225 - accuracy: 0.0622 - val_loss: 0.0209 - val_accuracy: 0.0880\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\nEpoch 10/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0217 - accuracy: 0.0699 - val_loss: 0.0205 - val_accuracy: 0.0914\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\nEpoch 11/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0212 - accuracy: 0.0708 - val_loss: 0.0201 - val_accuracy: 0.0673\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\nEpoch 12/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0208 - accuracy: 0.0751 - val_loss: 0.0198 - val_accuracy: 0.0815\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\nEpoch 13/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0207 - accuracy: 0.0765 - val_loss: 0.0197 - val_accuracy: 0.0991\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\nEpoch 14/20\n140/140 [==============================] - 9s 62ms/step - loss: 0.0204 - accuracy: 0.0772 - val_loss: 0.0196 - val_accuracy: 0.0757\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\nEpoch 15/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0203 - accuracy: 0.0800 - val_loss: 0.0194 - val_accuracy: 0.0910\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\nEpoch 16/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0200 - accuracy: 0.0801 - val_loss: 0.0193 - val_accuracy: 0.0932\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\nEpoch 17/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0200 - accuracy: 0.0822 - val_loss: 0.0193 - val_accuracy: 0.0949\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\nEpoch 18/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0199 - accuracy: 0.0832 - val_loss: 0.0192 - val_accuracy: 0.0848\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\nEpoch 19/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0199 - accuracy: 0.0811 - val_loss: 0.0191 - val_accuracy: 0.0964\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\nEpoch 20/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0199 - accuracy: 0.0842 - val_loss: 0.0191 - val_accuracy: 0.0888\nTotal time taken to fit model:  167.98697090148926  seconds\nGetting validation predictions...\nValidation log loss score: 0.01906872092740436\nCalculating final predictions...\nDone\nBeginning fold 2\nTRAIN INDEX: [    0     1     3 ... 23810 23811 23812] VALID INDEX: [    2    10    11 ... 23805 23806 23813]\nX_train    cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n0          1          0          1          0          0          1   \n1          1          0          0          1          0          1   \n3          1          0          0          0          1          1   \n4          1          0          0          1          0          0   \n5          1          0          1          0          0          1   \n\n   cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n0          0  1.0620  0.5577 -0.2479  ...  0.2862  0.2584  0.8076  0.5523   \n1          0  0.0743  0.4087  0.2991  ... -0.4265  0.7543  0.4708  0.0230   \n3          0 -0.5138 -0.2491 -0.2656  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4          1 -0.3254 -0.4009  0.9700  ...  0.0042  0.0048  0.6670  1.0690   \n5          0 -0.6111  0.2941 -0.9901  ...  1.8390  1.1570 -1.0120  1.9010   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n0 -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n1  0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n3 -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n5  1.4270  0.4519  1.2120  0.3765  0.7848  1.3990  \n\n[5 rows x 879 columns] \n\n\n\ny_train    5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n0                            0                       0               0   \n1                            0                       0               0   \n3                            0                       0               0   \n4                            0                       0               0   \n5                            0                       0               0   \n\n   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n0                               0                                  0   \n1                               0                                  0   \n3                               0                                  0   \n4                               0                                  0   \n5                               0                                  0   \n\n   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n0                               0                           0   \n1                               0                           0   \n3                               0                           0   \n4                               0                           0   \n5                               0                           0   \n\n   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n0                              0                           0   \n1                              0                           0   \n3                              0                           0   \n4                              0                           0   \n5                              0                           0   \n\n   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                            0  ...                                      0   \n1                            0  ...                                      0   \n3                            0  ...                                      0   \n4                            0  ...                                      0   \n5                            0  ...                                      0   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0             0                0                  0   \n1             0                0                  0   \n3             0                0                  0   \n4             0                0                  0   \n5             0                0                  0   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                          0                                      0   \n1                          0                                      0   \n3                          0                                      0   \n4                          0                                      0   \n5                          0                                      0   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0                0          0                           0              0  \n1                0          0                           0              0  \n3                0          0                           0              0  \n4                0          0                           0              0  \n5                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nX_valid     cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n2           1          0          0          0          1          1   \n10          1          0          0          1          0          0   \n11          1          0          0          0          1          0   \n12          1          0          0          0          1          1   \n14          1          0          0          1          0          1   \n\n    cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n2           0  0.6280  0.5817  1.5540  ... -0.7250 -0.6297  0.6103  0.0223   \n10          1 -0.2875  0.0322 -0.8863  ...  0.2050 -0.7286  0.4684 -0.1541   \n11          1 -0.3864 -0.5551 -0.8978  ...  0.2856 -0.1953  0.7269 -0.5909   \n12          0  0.0030  0.7189  1.8890  ...  1.1080 -0.3030  1.1730  0.7277   \n14          0  0.4242  1.7040 -1.3230  ... -5.9590 -0.6440 -0.3461 -4.9490   \n\n      c-94    c-95    c-96    c-97    c-98    c-99  \n2  -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n10  0.8135  1.4680  0.6648  0.0651 -0.0125  0.2600  \n11 -0.0241  0.0299  0.2731  0.6306  0.8285  0.3605  \n12  0.6671  0.7115  0.8592  0.2429  0.3453  0.3083  \n14 -1.1380 -5.2000 -8.1330 -4.3170 -6.2390  0.9477  \n\n[5 rows x 879 columns] \n\n\n\ny_valid     5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n2                             0                       0               0   \n10                            0                       0               0   \n11                            0                       0               0   \n12                            0                       0               0   \n14                            0                       0               0   \n\n    acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n2                                0                                  0   \n10                               0                                  0   \n11                               0                                  0   \n12                               0                                  0   \n14                               0                                  0   \n\n    acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n2                                0                           0   \n10                               0                           0   \n11                               0                           0   \n12                               0                           0   \n14                               0                           0   \n\n    adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n2                               0                           0   \n10                              0                           0   \n11                              0                           0   \n12                              0                           0   \n14                              0                           0   \n\n    adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n2                             0  ...                                      0   \n10                            0  ...                                      0   \n11                            0  ...                                      0   \n12                            0  ...                                      0   \n14                            0  ...                                      0   \n\n    trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n2              0                0                  0   \n10             0                0                  0   \n11             0                0                  0   \n12             0                0                  0   \n14             0                0                  0   \n\n    tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n2                           0                                      0   \n10                          0                                      0   \n11                          0                                      0   \n12                          0                                      0   \n14                          0                                      0   \n\n    vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n2                 0          0                           0              0  \n10                0          0                           0              0  \n11                0          0                           0              0  \n12                0          0                           0              0  \n14                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nBeginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\nLearning rate schedule: 0.0001 to 0.0003 to 1.4e-05\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\nEpoch 1/20\n140/140 [==============================] - 9s 62ms/step - loss: 0.0197 - accuracy: 0.0811 - val_loss: 0.0187 - val_accuracy: 0.0846\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\nEpoch 2/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0193 - accuracy: 0.0870 - val_loss: 0.0183 - val_accuracy: 0.1110\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\nEpoch 3/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0190 - accuracy: 0.0904 - val_loss: 0.0180 - val_accuracy: 0.1132\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\nEpoch 4/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0184 - accuracy: 0.0951 - val_loss: 0.0175 - val_accuracy: 0.0900\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\nEpoch 5/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0179 - accuracy: 0.0978 - val_loss: 0.0175 - val_accuracy: 0.1166\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 6/20\n140/140 [==============================] - 8s 57ms/step - loss: 0.0176 - accuracy: 0.1060 - val_loss: 0.0170 - val_accuracy: 0.1162\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 7/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0172 - accuracy: 0.1091 - val_loss: 0.0167 - val_accuracy: 0.0976\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 8/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0169 - accuracy: 0.1129 - val_loss: 0.0165 - val_accuracy: 0.1085\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\nEpoch 9/20\n140/140 [==============================] - 8s 61ms/step - loss: 0.0164 - accuracy: 0.1197 - val_loss: 0.0163 - val_accuracy: 0.1107\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\nEpoch 10/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0161 - accuracy: 0.1244 - val_loss: 0.0162 - val_accuracy: 0.1068\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\nEpoch 11/20\n140/140 [==============================] - 10s 68ms/step - loss: 0.0160 - accuracy: 0.1264 - val_loss: 0.0162 - val_accuracy: 0.1083\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\nEpoch 12/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0157 - accuracy: 0.1301 - val_loss: 0.0161 - val_accuracy: 0.1092\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\nEpoch 13/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0155 - accuracy: 0.1353 - val_loss: 0.0160 - val_accuracy: 0.1088\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\nEpoch 14/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0155 - accuracy: 0.1358 - val_loss: 0.0160 - val_accuracy: 0.1110\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\nEpoch 15/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0153 - accuracy: 0.1390 - val_loss: 0.0160 - val_accuracy: 0.1127\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\nEpoch 16/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.0152 - accuracy: 0.1414 - val_loss: 0.0160 - val_accuracy: 0.1130\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\nEpoch 17/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0152 - accuracy: 0.1368 - val_loss: 0.0160 - val_accuracy: 0.1125\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\nEpoch 18/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0151 - accuracy: 0.1440 - val_loss: 0.0159 - val_accuracy: 0.1129\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\nEpoch 19/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0151 - accuracy: 0.1460 - val_loss: 0.0159 - val_accuracy: 0.1135\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\nEpoch 20/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0151 - accuracy: 0.1478 - val_loss: 0.0159 - val_accuracy: 0.1135\nTotal time taken to fit model:  168.0632975101471  seconds\nGetting validation predictions...\nValidation log loss score: 0.01591271677629102\nCalculating final predictions...\nDone\nBeginning fold 3\nTRAIN INDEX: [    0     1     2 ... 23811 23812 23813] VALID INDEX: [    6     7    19 ... 23804 23807 23808]\nX_train    cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n0          1          0          1          0          0          1   \n1          1          0          0          1          0          1   \n2          1          0          0          0          1          1   \n3          1          0          0          0          1          1   \n4          1          0          0          1          0          0   \n\n   cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n0          0  1.0620  0.5577 -0.2479  ...  0.2862  0.2584  0.8076  0.5523   \n1          0  0.0743  0.4087  0.2991  ... -0.4265  0.7543  0.4708  0.0230   \n2          0  0.6280  0.5817  1.5540  ... -0.7250 -0.6297  0.6103  0.0223   \n3          0 -0.5138 -0.2491 -0.2656  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4          1 -0.3254 -0.4009  0.9700  ...  0.0042  0.0048  0.6670  1.0690   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n0 -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n1  0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n2 -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n3 -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n\n[5 rows x 879 columns] \n\n\n\ny_train    5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n0                            0                       0               0   \n1                            0                       0               0   \n2                            0                       0               0   \n3                            0                       0               0   \n4                            0                       0               0   \n\n   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n0                               0                                  0   \n1                               0                                  0   \n2                               0                                  0   \n3                               0                                  0   \n4                               0                                  0   \n\n   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n0                               0                           0   \n1                               0                           0   \n2                               0                           0   \n3                               0                           0   \n4                               0                           0   \n\n   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n0                              0                           0   \n1                              0                           0   \n2                              0                           0   \n3                              0                           0   \n4                              0                           0   \n\n   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                            0  ...                                      0   \n1                            0  ...                                      0   \n2                            0  ...                                      0   \n3                            0  ...                                      0   \n4                            0  ...                                      0   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0             0                0                  0   \n1             0                0                  0   \n2             0                0                  0   \n3             0                0                  0   \n4             0                0                  0   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                          0                                      0   \n1                          0                                      0   \n2                          0                                      0   \n3                          0                                      0   \n4                          0                                      0   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0                0          0                           0              0  \n1                0          0                           0              0  \n2                0          0                           0              0  \n3                0          0                           0              0  \n4                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nX_valid     cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n6           1          0          1          0          0          0   \n7           1          0          0          0          1          1   \n19          1          0          0          0          1          1   \n22          1          0          0          1          0          1   \n25          0          1          0          0          1          1   \n\n    cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n6           1  2.0440  1.7000 -1.5390  ...  0.1855  1.1720  0.8325  0.6486   \n7           0  0.2711  0.5133 -0.1327  ...  0.3230 -0.4140  0.2532  0.0513   \n19          0 -0.1428 -0.1957 -0.6397  ... -0.1851 -0.1995  0.3496  0.3608   \n22          0  0.6111 -0.2907 -0.7853  ...  0.0947  0.5732  0.0289  0.1109   \n25          0 -0.6696 -0.2718 -1.2230  ...  0.6171  0.6405  0.5429  0.3562   \n\n      c-94    c-95    c-96    c-97    c-98    c-99  \n6   0.8090  1.5880  2.4670  0.0357  0.1351 -0.3179  \n7   0.8600  1.4250  0.6633  0.4562 -0.9622  0.0260  \n19  0.7261 -0.0030  0.2853  0.3129  0.4251  0.4308  \n22  0.1208  0.5104  0.7287 -0.0168 -0.3555 -0.0509  \n25  1.3290  0.5573  0.8837  0.5534  0.8976  1.0050  \n\n[5 rows x 879 columns] \n\n\n\ny_valid     5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n6                             0                       0               0   \n7                             0                       0               0   \n19                            0                       0               0   \n22                            0                       0               0   \n25                            0                       0               0   \n\n    acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n6                                0                                  0   \n7                                0                                  0   \n19                               0                                  0   \n22                               0                                  0   \n25                               0                                  0   \n\n    acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n6                                0                           0   \n7                                0                           0   \n19                               0                           0   \n22                               0                           0   \n25                               0                           0   \n\n    adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n6                               0                           0   \n7                               0                           0   \n19                              0                           0   \n22                              0                           0   \n25                              0                           0   \n\n    adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n6                             0  ...                                      0   \n7                             0  ...                                      0   \n19                            0  ...                                      0   \n22                            0  ...                                      0   \n25                            0  ...                                      0   \n\n    trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n6              0                0                  0   \n7              0                0                  0   \n19             0                0                  0   \n22             0                0                  0   \n25             0                0                  0   \n\n    tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n6                           0                                      0   \n7                           0                                      0   \n19                          0                                      0   \n22                          0                                      0   \n25                          0                                      0   \n\n    vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n6                 0          0                           0              0  \n7                 0          0                           0              0  \n19                0          0                           0              0  \n22                0          0                           0              0  \n25                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nBeginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\nLearning rate schedule: 0.0001 to 0.0003 to 1.4e-05\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\nEpoch 1/20\n140/140 [==============================] - 9s 64ms/step - loss: 0.0158 - accuracy: 0.1318 - val_loss: 0.0142 - val_accuracy: 0.1515\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\nEpoch 2/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.0156 - accuracy: 0.1361 - val_loss: 0.0142 - val_accuracy: 0.1503\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\nEpoch 3/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0153 - accuracy: 0.1456 - val_loss: 0.0143 - val_accuracy: 0.1556\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\nEpoch 4/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0151 - accuracy: 0.1470 - val_loss: 0.0143 - val_accuracy: 0.1480\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\nEpoch 5/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0148 - accuracy: 0.1562 - val_loss: 0.0143 - val_accuracy: 0.1443\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 6/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0143 - accuracy: 0.1648 - val_loss: 0.0142 - val_accuracy: 0.1443\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 7/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0138 - accuracy: 0.1795 - val_loss: 0.0143 - val_accuracy: 0.1478\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 8/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0133 - accuracy: 0.1938 - val_loss: 0.0144 - val_accuracy: 0.1463\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\nEpoch 9/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0126 - accuracy: 0.2132 - val_loss: 0.0142 - val_accuracy: 0.1498\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\nEpoch 10/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0117 - accuracy: 0.2343 - val_loss: 0.0141 - val_accuracy: 0.1527\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\nEpoch 11/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0111 - accuracy: 0.2564 - val_loss: 0.0142 - val_accuracy: 0.1478\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\nEpoch 12/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0106 - accuracy: 0.2699 - val_loss: 0.0142 - val_accuracy: 0.1490\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\nEpoch 13/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0102 - accuracy: 0.2818 - val_loss: 0.0141 - val_accuracy: 0.1515\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\nEpoch 14/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0099 - accuracy: 0.2967 - val_loss: 0.0142 - val_accuracy: 0.1601\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\nEpoch 15/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0096 - accuracy: 0.3017 - val_loss: 0.0142 - val_accuracy: 0.1529\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\nEpoch 16/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0095 - accuracy: 0.3087 - val_loss: 0.0142 - val_accuracy: 0.1527\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\nEpoch 17/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0093 - accuracy: 0.3131 - val_loss: 0.0142 - val_accuracy: 0.1534\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\nEpoch 18/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0093 - accuracy: 0.3153 - val_loss: 0.0142 - val_accuracy: 0.1527\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\nEpoch 19/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0092 - accuracy: 0.3186 - val_loss: 0.0142 - val_accuracy: 0.1527\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\nEpoch 20/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0091 - accuracy: 0.3220 - val_loss: 0.0142 - val_accuracy: 0.1519\nTotal time taken to fit model:  167.29525208473206  seconds\nGetting validation predictions...\nValidation log loss score: 0.01421385203638285\nCalculating final predictions...\nDone\nBeginning fold 4\nTRAIN INDEX: [    1     2     5 ... 23809 23810 23813] VALID INDEX: [    0     3     4 ... 23802 23811 23812]\nX_train    cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n1          1          0          0          1          0          1   \n2          1          0          0          0          1          1   \n5          1          0          1          0          0          1   \n6          1          0          1          0          0          0   \n7          1          0          0          0          1          1   \n\n   cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n1          0  0.0743  0.4087  0.2991  ... -0.4265  0.7543  0.4708  0.0230   \n2          0  0.6280  0.5817  1.5540  ... -0.7250 -0.6297  0.6103  0.0223   \n5          0 -0.6111  0.2941 -0.9901  ...  1.8390  1.1570 -1.0120  1.9010   \n6          1  2.0440  1.7000 -1.5390  ...  0.1855  1.1720  0.8325  0.6486   \n7          0  0.2711  0.5133 -0.1327  ...  0.3230 -0.4140  0.2532  0.0513   \n\n     c-94    c-95    c-96    c-97    c-98    c-99  \n1  0.2957  0.4899  0.1522  0.1241  0.6077  0.7371  \n2 -1.3240 -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n5  1.4270  0.4519  1.2120  0.3765  0.7848  1.3990  \n6  0.8090  1.5880  2.4670  0.0357  0.1351 -0.3179  \n7  0.8600  1.4250  0.6633  0.4562 -0.9622  0.0260  \n\n[5 rows x 879 columns] \n\n\n\ny_train    5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n1                            0                       0               0   \n2                            0                       0               0   \n5                            0                       0               0   \n6                            0                       0               0   \n7                            0                       0               0   \n\n   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n1                               0                                  0   \n2                               0                                  0   \n5                               0                                  0   \n6                               0                                  0   \n7                               0                                  0   \n\n   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n1                               0                           0   \n2                               0                           0   \n5                               0                           0   \n6                               0                           0   \n7                               0                           0   \n\n   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n1                              0                           0   \n2                              0                           0   \n5                              0                           0   \n6                              0                           0   \n7                              0                           0   \n\n   adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n1                            0  ...                                      0   \n2                            0  ...                                      0   \n5                            0  ...                                      0   \n6                            0  ...                                      0   \n7                            0  ...                                      0   \n\n   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n1             0                0                  0   \n2             0                0                  0   \n5             0                0                  0   \n6             0                0                  0   \n7             0                0                  0   \n\n   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n1                          0                                      0   \n2                          0                                      0   \n5                          0                                      0   \n6                          0                                      0   \n7                          0                                      0   \n\n   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n1                0          0                           0              0  \n2                0          0                           0              0  \n5                0          0                           0              0  \n6                0          0                           0              0  \n7                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nX_valid     cp_type_1  cp_type_2  cp_time_1  cp_time_2  cp_time_3  cp_dose_1  \\\n0           1          0          1          0          0          1   \n3           1          0          0          0          1          1   \n4           1          0          0          1          0          0   \n13          1          0          0          0          1          0   \n15          1          0          0          0          1          1   \n\n    cp_dose_2     g-0     g-1     g-2  ...    c-90    c-91    c-92    c-93  \\\n0           0  1.0620  0.5577 -0.2479  ...  0.2862  0.2584  0.8076  0.5523   \n3           0 -0.5138 -0.2491 -0.2656  ... -2.0990 -0.6441 -5.6300 -1.3780   \n4           1 -0.3254 -0.4009  0.9700  ...  0.0042  0.0048  0.6670  1.0690   \n13          1 -0.6884 -0.4203 -1.2640  ... -0.9147  0.3180 -0.7729 -0.4888   \n15          0  0.0667 -0.6472 -0.2440  ...  0.5732  0.2724 -0.1616  1.3010   \n\n      c-94    c-95    c-96    c-97    c-98    c-99  \n0  -0.1912  0.6584 -0.3981  0.2139  0.3801  0.4176  \n3  -0.8632 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n4   0.5523 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n13 -0.7573  0.8023  0.0506 -0.1909  0.7842 -0.6606  \n15  0.7263  1.1690 -0.5595 -0.5456  0.7705  0.5639  \n\n[5 rows x 879 columns] \n\n\n\ny_valid     5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n0                             0                       0               0   \n3                             0                       0               0   \n4                             0                       0               0   \n13                            0                       0               0   \n15                            0                       0               0   \n\n    acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n0                                0                                  0   \n3                                0                                  0   \n4                                0                                  0   \n13                               0                                  0   \n15                               0                                  0   \n\n    acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n0                                0                           0   \n3                                0                           0   \n4                                0                           0   \n13                               0                           0   \n15                               0                           0   \n\n    adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n0                               0                           0   \n3                               0                           0   \n4                               0                           0   \n13                              0                           0   \n15                              0                           0   \n\n    adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                             0  ...                                      0   \n3                             0  ...                                      0   \n4                             0  ...                                      0   \n13                            0  ...                                      0   \n15                            0  ...                                      0   \n\n    trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0              0                0                  0   \n3              0                0                  0   \n4              0                0                  0   \n13             0                0                  0   \n15             0                0                  0   \n\n    tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                           0                                      0   \n3                           0                                      0   \n4                           0                                      0   \n13                          0                                      0   \n15                          0                                      0   \n\n    vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0                 0          0                           0              0  \n3                 0          0                           0              0  \n4                 0          0                           0              0  \n13                0          0                           0              0  \n15                0          0                           0              0  \n\n[5 rows x 206 columns] \n\n\n\nBeginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\nLearning rate schedule: 0.0001 to 0.0003 to 1.4e-05\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\nEpoch 1/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0117 - accuracy: 0.2591 - val_loss: 0.0070 - val_accuracy: 0.3939\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\nEpoch 2/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0113 - accuracy: 0.2639 - val_loss: 0.0074 - val_accuracy: 0.3800\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\nEpoch 3/20\n140/140 [==============================] - 9s 61ms/step - loss: 0.0109 - accuracy: 0.2752 - val_loss: 0.0077 - val_accuracy: 0.3674\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\nEpoch 4/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0105 - accuracy: 0.2871 - val_loss: 0.0080 - val_accuracy: 0.3622\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\nEpoch 5/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0099 - accuracy: 0.3036 - val_loss: 0.0083 - val_accuracy: 0.3309\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 6/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0094 - accuracy: 0.3152 - val_loss: 0.0086 - val_accuracy: 0.3146\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 7/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0086 - accuracy: 0.3376 - val_loss: 0.0089 - val_accuracy: 0.3049\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\nEpoch 8/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0080 - accuracy: 0.3635 - val_loss: 0.0092 - val_accuracy: 0.2889\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\nEpoch 9/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0070 - accuracy: 0.3985 - val_loss: 0.0090 - val_accuracy: 0.3052\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\nEpoch 10/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0060 - accuracy: 0.4300 - val_loss: 0.0090 - val_accuracy: 0.2946\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\nEpoch 11/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0054 - accuracy: 0.4520 - val_loss: 0.0090 - val_accuracy: 0.3010\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\nEpoch 12/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0050 - accuracy: 0.4677 - val_loss: 0.0089 - val_accuracy: 0.2973\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\nEpoch 13/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0045 - accuracy: 0.4747 - val_loss: 0.0089 - val_accuracy: 0.2946\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\nEpoch 14/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0043 - accuracy: 0.4824 - val_loss: 0.0089 - val_accuracy: 0.2968\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\nEpoch 15/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0042 - accuracy: 0.4842 - val_loss: 0.0089 - val_accuracy: 0.2956\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\nEpoch 16/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0040 - accuracy: 0.4919 - val_loss: 0.0089 - val_accuracy: 0.2960\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\nEpoch 17/20\n140/140 [==============================] - 8s 60ms/step - loss: 0.0039 - accuracy: 0.4933 - val_loss: 0.0090 - val_accuracy: 0.2963\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\nEpoch 18/20\n140/140 [==============================] - 9s 64ms/step - loss: 0.0038 - accuracy: 0.4976 - val_loss: 0.0090 - val_accuracy: 0.2968\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\nEpoch 19/20\n140/140 [==============================] - 8s 58ms/step - loss: 0.0038 - accuracy: 0.4975 - val_loss: 0.0090 - val_accuracy: 0.2980\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\nEpoch 20/20\n140/140 [==============================] - 8s 59ms/step - loss: 0.0037 - accuracy: 0.5015 - val_loss: 0.0090 - val_accuracy: 0.2988\nTotal time taken to fit model:  167.70174193382263  seconds\nGetting validation predictions...\nValidation log loss score: 0.008965847525074627\nCalculating final predictions...\nDone\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Show all CV scores\n\nprint('Cross Validation scores: ',cv_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Ensemble final predictions\n\nprint('Ensembling final predictions')\nfinal_predictions = np.mean(np.array(final_preds),axis=0)\n\nprint('Done')","execution_count":132,"outputs":[{"output_type":"stream","text":"Ensembling final predictions\nDone\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Output results"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Output final predictions\n\nsample_sub_df.iloc[:,1:] = final_predictions\nsample_sub_df.to_csv('submission.csv',index=False)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Insight into final predictions\n\nsample_sub_df.describe()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"       5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\ncount                  3982.000000             3982.000000     3982.000000   \nmean                      0.000370                0.000328        0.000484   \nstd                       0.004141                0.002580        0.005056   \nmin                       0.000002                0.000003        0.000001   \n25%                       0.000111                0.000123        0.000204   \n50%                       0.000211                0.000233        0.000318   \n75%                       0.000327                0.000345        0.000449   \nmax                       0.210134                0.125887        0.282515   \n\n       acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\ncount                    3.982000e+03                       3.982000e+03   \nmean                     7.120143e-03                       1.046316e-02   \nstd                      3.098040e-02                       2.679376e-02   \nmin                      9.170964e-07                       8.501720e-07   \n25%                      1.002858e-03                       1.911399e-03   \n50%                      1.927934e-03                       5.034471e-03   \n75%                      3.171309e-03                       8.548996e-03   \nmax                      3.382726e-01                       3.290400e-01   \n\n       acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\ncount                    3.982000e+03                3.982000e+03   \nmean                     1.798287e-03                1.119509e-03   \nstd                      1.196302e-02                5.672261e-03   \nmin                      9.982148e-07                8.135466e-07   \n25%                      4.401475e-04                5.039043e-04   \n50%                      9.160799e-04                8.358637e-04   \n75%                      1.351897e-03                1.148176e-03   \nmax                      2.700277e-01                2.440673e-01   \n\n       adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\ncount                   3.982000e+03                 3982.000000   \nmean                    2.407543e-03                    0.000171   \nstd                     1.405394e-02                    0.000132   \nmin                     4.057433e-07                    0.000008   \n25%                     6.328827e-04                    0.000097   \n50%                     1.217232e-03                    0.000158   \n75%                     1.844543e-03                    0.000229   \nmax                     3.350974e-01                    0.004719   \n\n       adrenergic_receptor_agonist  ...  \\\ncount                 3.982000e+03  ...   \nmean                  1.240592e-02  ...   \nstd                   3.728027e-02  ...   \nmin                   2.552764e-07  ...   \n25%                   1.885073e-03  ...   \n50%                   4.782439e-03  ...   \n75%                   8.615820e-03  ...   \nmax                   3.878667e-01  ...   \n\n       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\ncount                            3982.000000   3982.000000      3982.000000   \nmean                                0.000136      0.000414         0.000785   \nstd                                 0.000175      0.005480         0.002849   \nmin                                 0.000006      0.000002         0.000001   \n25%                                 0.000081      0.000103         0.000363   \n50%                                 0.000121      0.000200         0.000565   \n75%                                 0.000169      0.000366         0.000811   \nmax                                 0.007840      0.338085         0.139170   \n\n       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\ncount        3982.000000               3.982000e+03   \nmean            0.011926               2.007071e-03   \nstd             0.092728               1.130211e-02   \nmin             0.000002               6.148182e-07   \n25%             0.000169               2.507711e-04   \n50%             0.000422               5.794931e-04   \n75%             0.001036               1.315991e-03   \nmax             0.995495               3.323653e-01   \n\n       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor    vitamin_b  \\\ncount                            3982.000000      3982.000000  3982.000000   \nmean                                0.000150         0.005570     0.000393   \nstd                                 0.000101         0.039146     0.000746   \nmin                                 0.000004         0.000002     0.000001   \n25%                                 0.000086         0.000118     0.000209   \n50%                                 0.000138         0.000339     0.000329   \n75%                                 0.000198         0.001118     0.000461   \nmax                                 0.002651         0.965009     0.032504   \n\n       vitamin_d_receptor_agonist  wnt_inhibitor  \ncount                 3982.000000    3982.000000  \nmean                     0.001431       0.000522  \nstd                      0.020371       0.002465  \nmin                      0.000001       0.000002  \n25%                      0.000276       0.000268  \n50%                      0.000494       0.000421  \n75%                      0.000754       0.000572  \nmax                      0.665003       0.129687  \n\n[8 rows x 206 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>...</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3.982000e+03</td>\n      <td>3982.000000</td>\n      <td>3.982000e+03</td>\n      <td>...</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3.982000e+03</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n      <td>3982.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000370</td>\n      <td>0.000328</td>\n      <td>0.000484</td>\n      <td>7.120143e-03</td>\n      <td>1.046316e-02</td>\n      <td>1.798287e-03</td>\n      <td>1.119509e-03</td>\n      <td>2.407543e-03</td>\n      <td>0.000171</td>\n      <td>1.240592e-02</td>\n      <td>...</td>\n      <td>0.000136</td>\n      <td>0.000414</td>\n      <td>0.000785</td>\n      <td>0.011926</td>\n      <td>2.007071e-03</td>\n      <td>0.000150</td>\n      <td>0.005570</td>\n      <td>0.000393</td>\n      <td>0.001431</td>\n      <td>0.000522</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.004141</td>\n      <td>0.002580</td>\n      <td>0.005056</td>\n      <td>3.098040e-02</td>\n      <td>2.679376e-02</td>\n      <td>1.196302e-02</td>\n      <td>5.672261e-03</td>\n      <td>1.405394e-02</td>\n      <td>0.000132</td>\n      <td>3.728027e-02</td>\n      <td>...</td>\n      <td>0.000175</td>\n      <td>0.005480</td>\n      <td>0.002849</td>\n      <td>0.092728</td>\n      <td>1.130211e-02</td>\n      <td>0.000101</td>\n      <td>0.039146</td>\n      <td>0.000746</td>\n      <td>0.020371</td>\n      <td>0.002465</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000002</td>\n      <td>0.000003</td>\n      <td>0.000001</td>\n      <td>9.170964e-07</td>\n      <td>8.501720e-07</td>\n      <td>9.982148e-07</td>\n      <td>8.135466e-07</td>\n      <td>4.057433e-07</td>\n      <td>0.000008</td>\n      <td>2.552764e-07</td>\n      <td>...</td>\n      <td>0.000006</td>\n      <td>0.000002</td>\n      <td>0.000001</td>\n      <td>0.000002</td>\n      <td>6.148182e-07</td>\n      <td>0.000004</td>\n      <td>0.000002</td>\n      <td>0.000001</td>\n      <td>0.000001</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000111</td>\n      <td>0.000123</td>\n      <td>0.000204</td>\n      <td>1.002858e-03</td>\n      <td>1.911399e-03</td>\n      <td>4.401475e-04</td>\n      <td>5.039043e-04</td>\n      <td>6.328827e-04</td>\n      <td>0.000097</td>\n      <td>1.885073e-03</td>\n      <td>...</td>\n      <td>0.000081</td>\n      <td>0.000103</td>\n      <td>0.000363</td>\n      <td>0.000169</td>\n      <td>2.507711e-04</td>\n      <td>0.000086</td>\n      <td>0.000118</td>\n      <td>0.000209</td>\n      <td>0.000276</td>\n      <td>0.000268</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000211</td>\n      <td>0.000233</td>\n      <td>0.000318</td>\n      <td>1.927934e-03</td>\n      <td>5.034471e-03</td>\n      <td>9.160799e-04</td>\n      <td>8.358637e-04</td>\n      <td>1.217232e-03</td>\n      <td>0.000158</td>\n      <td>4.782439e-03</td>\n      <td>...</td>\n      <td>0.000121</td>\n      <td>0.000200</td>\n      <td>0.000565</td>\n      <td>0.000422</td>\n      <td>5.794931e-04</td>\n      <td>0.000138</td>\n      <td>0.000339</td>\n      <td>0.000329</td>\n      <td>0.000494</td>\n      <td>0.000421</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000327</td>\n      <td>0.000345</td>\n      <td>0.000449</td>\n      <td>3.171309e-03</td>\n      <td>8.548996e-03</td>\n      <td>1.351897e-03</td>\n      <td>1.148176e-03</td>\n      <td>1.844543e-03</td>\n      <td>0.000229</td>\n      <td>8.615820e-03</td>\n      <td>...</td>\n      <td>0.000169</td>\n      <td>0.000366</td>\n      <td>0.000811</td>\n      <td>0.001036</td>\n      <td>1.315991e-03</td>\n      <td>0.000198</td>\n      <td>0.001118</td>\n      <td>0.000461</td>\n      <td>0.000754</td>\n      <td>0.000572</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.210134</td>\n      <td>0.125887</td>\n      <td>0.282515</td>\n      <td>3.382726e-01</td>\n      <td>3.290400e-01</td>\n      <td>2.700277e-01</td>\n      <td>2.440673e-01</td>\n      <td>3.350974e-01</td>\n      <td>0.004719</td>\n      <td>3.878667e-01</td>\n      <td>...</td>\n      <td>0.007840</td>\n      <td>0.338085</td>\n      <td>0.139170</td>\n      <td>0.995495</td>\n      <td>3.323653e-01</td>\n      <td>0.002651</td>\n      <td>0.965009</td>\n      <td>0.032504</td>\n      <td>0.665003</td>\n      <td>0.129687</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows  206 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}