{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026508,
     "end_time": "2020-09-17T01:05:11.773609",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.747101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02357,
     "end_time": "2020-09-17T01:05:11.821663",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.798093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This kernel serves as a stratified k-fold ensemble approach baseline for the MoA (Mechanisms of Action) kaggle competition. The 3 models I have seen mostly used for this competition are Neural Networks, XGBoost (or some other boosted tree model), and Logistic Regression. Here I present a simple starter notebook to ensemble these three models with cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025626,
     "end_time": "2020-09-17T01:05:11.870929",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.845303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are many ways to improve the validation and leaderboard score from this notebook. Here are some ideas to experiment with:\n",
    "* Principal Component Analysis\n",
    "* Grid search to optimize model hyperparameters\n",
    "* Experimenting with number of epochs, number of layers, types of layers, learning rate, etc. for Neural Network\n",
    "* Bagging/boosting with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023891,
     "end_time": "2020-09-17T01:05:11.919395",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.895504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting everything ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0242,
     "end_time": "2020-09-17T01:05:11.967395",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.943195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will be using a multi-label stratified K-fold. Scikit-learn doesn't support this, but there is one located in this GitHub repository: [https://github.com/trent-b/iterative-stratification](http://) . We would normally be able to install this package with a simple pip command, but the competition rules state no internet use is allowed. Therefore, we will have to manually add this to our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:12.030659Z",
     "iopub.status.busy": "2020-09-17T01:05:12.030000Z",
     "iopub.status.idle": "2020-09-17T01:05:19.364763Z",
     "shell.execute_reply": "2020-09-17T01:05:19.363200Z"
    },
    "papermill": {
     "duration": 7.370945,
     "end_time": "2020-09-17T01:05:19.364893",
     "exception": false,
     "start_time": "2020-09-17T01:05:11.993948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Importing necessary libraries\n",
    "\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/iterativestratification') # Multilabel Stratified K-Fold package\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import time\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:19.427893Z",
     "iopub.status.busy": "2020-09-17T01:05:19.426886Z",
     "iopub.status.idle": "2020-09-17T01:05:19.429848Z",
     "shell.execute_reply": "2020-09-17T01:05:19.429345Z"
    },
    "papermill": {
     "duration": 0.03877,
     "end_time": "2020-09-17T01:05:19.429951",
     "exception": false,
     "start_time": "2020-09-17T01:05:19.391181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Settings\n",
    "\n",
    "SEED = 2020 \n",
    "FOLDS = 4\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "# Which models to use\n",
    "include_xgboost = True\n",
    "include_neural_net = True\n",
    "include_logreg = False\n",
    "\n",
    "\n",
    "lr_start=0.0001\n",
    "lr_max=0.0003\n",
    "lr_min=0.00001\n",
    "lr_rampup_epochs=5\n",
    "lr_sustain_epochs=2\n",
    "lr_exp_decay=.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:19.491296Z",
     "iopub.status.busy": "2020-09-17T01:05:19.490359Z",
     "iopub.status.idle": "2020-09-17T01:05:25.424726Z",
     "shell.execute_reply": "2020-09-17T01:05:25.423499Z"
    },
    "papermill": {
     "duration": 5.969808,
     "end_time": "2020-09-17T01:05:25.424847",
     "exception": false,
     "start_time": "2020-09-17T01:05:19.455039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Creating dataframes\n",
    "\n",
    "TEST_FEATURES_PATH = \"/kaggle/input/lish-moa/test_features.csv\"\n",
    "TRAIN_FEATURES_PATH = \"/kaggle/input/lish-moa/train_features.csv\"\n",
    "TRAIN_TARGETS_PATH = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\n",
    "TRAIN_TARGETS_NONSCORED_PATH = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\n",
    "SAMPLE_SUB_PATH = \"/kaggle/input/lish-moa/sample_submission.csv\"\n",
    "\n",
    "test_features_df = pd.read_csv(TEST_FEATURES_PATH).sort_values(by='sig_id')\n",
    "train_features_df = pd.read_csv(TRAIN_FEATURES_PATH).sort_values(by='sig_id')\n",
    "train_targets_df = pd.read_csv(TRAIN_TARGETS_PATH).sort_values(by='sig_id')\n",
    "train_targets_nonscored_df = pd.read_csv(TRAIN_TARGETS_NONSCORED_PATH)\n",
    "sample_sub_df = pd.read_csv(SAMPLE_SUB_PATH).sort_values(by='sig_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028485,
     "end_time": "2020-09-17T01:05:25.480896",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.452411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Understanding our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:25.540424Z",
     "iopub.status.busy": "2020-09-17T01:05:25.538503Z",
     "iopub.status.idle": "2020-09-17T01:05:25.541664Z",
     "shell.execute_reply": "2020-09-17T01:05:25.542269Z"
    },
    "papermill": {
     "duration": 0.035586,
     "end_time": "2020-09-17T01:05:25.542435",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.506849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Features\n",
    "#print(train_features_df.head()) \n",
    "#print(train_features_df.describe())\n",
    "\n",
    "\n",
    "### Labels\n",
    "#print(train_targets_df.head())\n",
    "#print(train_targets_df.describe())\n",
    "\n",
    "\n",
    "### Submission\n",
    "#print(sample_sub_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025701,
     "end_time": "2020-09-17T01:05:25.595814",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.570113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are using 875 features to predict binary labels on 206 different classes. We have 23,814 instances to train on, and each instance can be multiple different classes. This makes this a multi-label classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026159,
     "end_time": "2020-09-17T01:05:25.647319",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.621160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is always a good idea to look at the distribution of positive vs negative labels in each class. This helps us know how to split our training data better, and know what to look for in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:25.722281Z",
     "iopub.status.busy": "2020-09-17T01:05:25.719932Z",
     "iopub.status.idle": "2020-09-17T01:05:25.911511Z",
     "shell.execute_reply": "2020-09-17T01:05:25.910721Z"
    },
    "papermill": {
     "duration": 0.237718,
     "end_time": "2020-09-17T01:05:25.911698",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.673980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1   6   6   6   6   6   6   6   6   6   6   6   6   6   6   6\n",
      "   6   7   7   7   7  12  12  12  12  12  12  12  12  12  12  12  13  13\n",
      "  17  18  18  18  18  18  18  18  18  18  18  18  18  18  19  19  19  19\n",
      "  23  23  24  24  24  24  24  25  25  25  25  25  25  25  25  26  26  26\n",
      "  29  30  30  30  30  30  30  31  31  31  31  32  35  36  36  36  36  36\n",
      "  36  36  36  36  36  36  36  37  37  37  37  37  37  38  39  42  42  42\n",
      "  42  43  44  47  48  48  48  48  48  48  48  49  50  51  54  54  54  55\n",
      "  55  56  56  59  60  60  60  61  61  61  62  62  66  67  67  68  71  72\n",
      "  72  72  73  73  73  73  73  74  74  80  80  84  85  89  89  92  93  96\n",
      "  96  96  97  98 102 103 104 106 106 115 115 119 121 127 130 151 158 165\n",
      " 170 190 192 223 236 241 264 266 267 270 273 279 281 283 297 301 316 336\n",
      " 340 360 367 402 404 424 435 726 832]\n"
     ]
    }
   ],
   "source": [
    "### Check how many positive labels are in each class\n",
    "\n",
    "value_counts_arr = np.sort([train_targets_df[col].value_counts()[1] for col in train_targets_df.columns])\n",
    "\n",
    "print(value_counts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:25.976043Z",
     "iopub.status.busy": "2020-09-17T01:05:25.975280Z",
     "iopub.status.idle": "2020-09-17T01:05:26.290618Z",
     "shell.execute_reply": "2020-09-17T01:05:26.290075Z"
    },
    "papermill": {
     "duration": 0.349641,
     "end_time": "2020-09-17T01:05:26.290756",
     "exception": false,
     "start_time": "2020-09-17T01:05:25.941115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot histogram of 1s counts in classes \n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "plt.hist(value_counts_arr, 50, facecolor='g', alpha=0.75)\n",
    "plt.xlabel('Number of 1\\'s')\n",
    "plt.ylabel('Number of classes')\n",
    "plt.title('Value Counts of 1\\'s in classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028994,
     "end_time": "2020-09-17T01:05:26.349976",
     "exception": false,
     "start_time": "2020-09-17T01:05:26.320982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, there is a significantly small amount of positive labels in many classes. Three classes only have one positive instance! We must make sure we have these instances in the training set and not the validation set, or else our model will only predict one class! This is why we have to use a stratified k-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027141,
     "end_time": "2020-09-17T01:05:26.404479",
     "exception": false,
     "start_time": "2020-09-17T01:05:26.377338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026844,
     "end_time": "2020-09-17T01:05:26.458316",
     "exception": false,
     "start_time": "2020-09-17T01:05:26.431472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I decided to use One-Hot encoding for the categorical features. There are several other encoders to try that may perform better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:26.521000Z",
     "iopub.status.busy": "2020-09-17T01:05:26.520060Z",
     "iopub.status.idle": "2020-09-17T01:05:27.595482Z",
     "shell.execute_reply": "2020-09-17T01:05:27.596189Z"
    },
    "papermill": {
     "duration": 1.109834,
     "end_time": "2020-09-17T01:05:27.596373",
     "exception": false,
     "start_time": "2020-09-17T01:05:26.486539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "### Dealing w/ categorical features\n",
    "\n",
    "\n",
    "# Encode training categorical features\n",
    "enc1 = ce.OneHotEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(train_features_df)\n",
    "train_features_enc_df = enc1.transform(train_features_df)\n",
    "\n",
    "# Encode testing categorical features\n",
    "enc2 = ce.OneHotEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(test_features_df)\n",
    "test_features_enc_df = enc2.transform(test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:27.658546Z",
     "iopub.status.busy": "2020-09-17T01:05:27.657917Z",
     "iopub.status.idle": "2020-09-17T01:05:27.662908Z",
     "shell.execute_reply": "2020-09-17T01:05:27.662309Z"
    },
    "papermill": {
     "duration": 0.037139,
     "end_time": "2020-09-17T01:05:27.663020",
     "exception": false,
     "start_time": "2020-09-17T01:05:27.625881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Verify\n",
    "\n",
    "#print(train_features_enc_df.head())\n",
    "#print(train_features_enc_df.describe())\n",
    "\n",
    "#print(test_features_enc_df.head())\n",
    "#print(test_features_enc_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:27.724039Z",
     "iopub.status.busy": "2020-09-17T01:05:27.723340Z",
     "iopub.status.idle": "2020-09-17T01:05:27.727786Z",
     "shell.execute_reply": "2020-09-17T01:05:27.727143Z"
    },
    "papermill": {
     "duration": 0.036469,
     "end_time": "2020-09-17T01:05:27.727930",
     "exception": false,
     "start_time": "2020-09-17T01:05:27.691461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Initialize stratified k-fold object\n",
    "\n",
    "skf = MultilabelStratifiedKFold(n_splits = FOLDS,random_state=SEED,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:27.841686Z",
     "iopub.status.busy": "2020-09-17T01:05:27.839776Z",
     "iopub.status.idle": "2020-09-17T01:05:27.864984Z",
     "shell.execute_reply": "2020-09-17T01:05:27.864374Z"
    },
    "papermill": {
     "duration": 0.109093,
     "end_time": "2020-09-17T01:05:27.865107",
     "exception": false,
     "start_time": "2020-09-17T01:05:27.756014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Rename dataframes and drop 'id' columns\n",
    "\n",
    "X = train_features_enc_df.drop(columns=['sig_id'])\n",
    "X_test = test_features_enc_df.drop(columns=['sig_id'])\n",
    "y = train_targets_df.drop(columns=['sig_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045973,
     "end_time": "2020-09-17T01:05:27.958936",
     "exception": false,
     "start_time": "2020-09-17T01:05:27.912963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046673,
     "end_time": "2020-09-17T01:05:28.050747",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.004074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "My neural network contains 3 hidden layers, with batch normalization and dropout. This architecture is very simple (trains in only a few seconds w/ GPU) and should be experimented with to see what works best. Be sure to keep the last layer's activation as 'sigmoid' so that the outputs are all in [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.157137Z",
     "iopub.status.busy": "2020-09-17T01:05:28.156187Z",
     "iopub.status.idle": "2020-09-17T01:05:28.162055Z",
     "shell.execute_reply": "2020-09-17T01:05:28.163805Z"
    },
    "papermill": {
     "duration": 0.060964,
     "end_time": "2020-09-17T01:05:28.163993",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.103029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tf_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        L.Flatten(input_shape=(1,879)),\n",
    "        L.Dense(2000, activation='relu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(.4),\n",
    "        L.Dense(1000, activation='relu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(.4),\n",
    "        L.Dense(1000, activation='relu'),\n",
    "        L.BatchNormalization(),\n",
    "        L.Dropout(.4),\n",
    "        L.Dense(206, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040581,
     "end_time": "2020-09-17T01:05:28.249026",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.208445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This type of learning rate schedule has become the go-to for Kaggle competitions. It starts out small, ramps up to a certain threshold for a couple epochs, then decays exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.340677Z",
     "iopub.status.busy": "2020-09-17T01:05:28.339822Z",
     "iopub.status.idle": "2020-09-17T01:05:28.344535Z",
     "shell.execute_reply": "2020-09-17T01:05:28.345210Z"
    },
    "papermill": {
     "duration": 0.054981,
     "end_time": "2020-09-17T01:05:28.345374",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.290393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### learning rate schedule\n",
    "\n",
    "def lrfn(epoch):\n",
    "    \n",
    "    if epoch < lr_rampup_epochs:\n",
    "        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "        lr = lr_max\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.474795Z",
     "iopub.status.busy": "2020-09-17T01:05:28.474028Z",
     "iopub.status.idle": "2020-09-17T01:05:28.477259Z",
     "shell.execute_reply": "2020-09-17T01:05:28.477919Z"
    },
    "papermill": {
     "duration": 0.074416,
     "end_time": "2020-09-17T01:05:28.478073",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.403657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lr():\n",
    "    rng = [i for i in range(EPOCHS)]\n",
    "    y = [lrfn(x) for x in rng]\n",
    "    plt.plot(rng, y)\n",
    "    print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.603171Z",
     "iopub.status.busy": "2020-09-17T01:05:28.601260Z",
     "iopub.status.idle": "2020-09-17T01:05:28.607539Z",
     "shell.execute_reply": "2020-09-17T01:05:28.608653Z"
    },
    "papermill": {
     "duration": 0.068274,
     "end_time": "2020-09-17T01:05:28.608812",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.540538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Fit model\n",
    "\n",
    "def fit_model(model,X_train,X_valid,y_train,y_valid):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    print('Beginning to fit ',type(model))\n",
    "\n",
    "    if 'tensorflow' in str(type(model)): # Fit neural net model\n",
    "    \n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[lr_schedule],\n",
    "            validation_data=(X_valid,y_valid)\n",
    "        )\n",
    "    \n",
    "    else: # Fit other type of model\n",
    "    \n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "    print('Total time taken to fit model: ', time.time() - start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.703411Z",
     "iopub.status.busy": "2020-09-17T01:05:28.702662Z",
     "iopub.status.idle": "2020-09-17T01:05:28.707786Z",
     "shell.execute_reply": "2020-09-17T01:05:28.708835Z"
    },
    "papermill": {
     "duration": 0.0574,
     "end_time": "2020-09-17T01:05:28.708984",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.651584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Make Predictions\n",
    "\n",
    "def get_preds(model,X_valid,final=False):\n",
    "\n",
    "    if 'tensorflow' in str(type(model)): # Neural Network model predictions \n",
    "        \n",
    "        if final==True:\n",
    "            preds = np.array(model.predict(X_test).astype(\"float64\"))\n",
    "        else:\n",
    "            preds = np.array(model.predict(X_valid).astype(\"float64\"))\n",
    "            \n",
    "    else:    # Other model predictions          \n",
    "        \n",
    "        if final==True:\n",
    "            preds = np.array(model.predict_proba(X_test))\n",
    "        else:\n",
    "            preds = np.array(model.predict_proba(X_valid))\n",
    "        \n",
    "        preds = preds[:,:,1].T\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.799284Z",
     "iopub.status.busy": "2020-09-17T01:05:28.797890Z",
     "iopub.status.idle": "2020-09-17T01:05:28.800034Z",
     "shell.execute_reply": "2020-09-17T01:05:28.800678Z"
    },
    "papermill": {
     "duration": 0.040746,
     "end_time": "2020-09-17T01:05:28.800806",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.760060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Calculate validation score\n",
    "\n",
    "def calc_loss(vals,preds):\n",
    "\n",
    "    score = log_loss(np.ravel(vals),np.ravel(preds))\n",
    "    \n",
    "    cv_scores.append(score)\n",
    "\n",
    "    print('Validation log loss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.888906Z",
     "iopub.status.busy": "2020-09-17T01:05:28.887990Z",
     "iopub.status.idle": "2020-09-17T01:05:28.892147Z",
     "shell.execute_reply": "2020-09-17T01:05:28.893236Z"
    },
    "papermill": {
     "duration": 0.054346,
     "end_time": "2020-09-17T01:05:28.893422",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.839076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(model,X_train,X_valid,y_train,y_valid):\n",
    "\n",
    "    ### fit the model\n",
    "    fit_model(model,X_train,X_valid,y_train,y_valid)\n",
    "\n",
    "    print('Getting validation predictions...')\n",
    "    \n",
    "    ### get the predictions\n",
    "    temp_val_preds = get_preds(model,X_valid,final=False)\n",
    "    \n",
    "    ### calculate log loss\n",
    "    calc_loss(y_valid,temp_val_preds)\n",
    "    \n",
    "    print('Calculating final predictions...')\n",
    "\n",
    "    ### final preds\n",
    "    final_preds.append(get_preds(model,X_valid,final=True))\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:28.991459Z",
     "iopub.status.busy": "2020-09-17T01:05:28.989289Z",
     "iopub.status.idle": "2020-09-17T01:05:28.995697Z",
     "shell.execute_reply": "2020-09-17T01:05:28.997241Z"
    },
    "papermill": {
     "duration": 0.058886,
     "end_time": "2020-09-17T01:05:28.997406",
     "exception": false,
     "start_time": "2020-09-17T01:05:28.938520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### XGBoost Model\n",
    "\n",
    "if include_xgboost == True:\n",
    "    \n",
    "    model_1 = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n",
    "\n",
    "    # The MultiOutputClassifier wrapper creates one model for each class (i.e. 206 different models total)\n",
    "\n",
    "    # Using parameters from https://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification\n",
    "    params = {'estimator__colsample_bytree': 0.6522,\n",
    "          'estimator__gamma': 3.6975,\n",
    "          'estimator__learning_rate': 0.0503,\n",
    "          'estimator__max_delta_step': 2.0706,\n",
    "          'estimator__max_depth': 10,\n",
    "          'estimator__min_child_weight': 31.5800,\n",
    "          'estimator__n_estimators': 166,\n",
    "          'estimator__subsample': 0.8639\n",
    "         }\n",
    "\n",
    "    model_1.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:29.102146Z",
     "iopub.status.busy": "2020-09-17T01:05:29.099833Z",
     "iopub.status.idle": "2020-09-17T01:05:32.515188Z",
     "shell.execute_reply": "2020-09-17T01:05:32.514158Z"
    },
    "papermill": {
     "duration": 3.475318,
     "end_time": "2020-09-17T01:05:32.515312",
     "exception": false,
     "start_time": "2020-09-17T01:05:29.039994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 0.0001 to 0.0003 to 1.07e-05\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 879)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              1760000   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 206)               206206    \n",
      "=================================================================\n",
      "Total params: 4,984,206\n",
      "Trainable params: 4,976,206\n",
      "Non-trainable params: 8,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Neural Network Model\n",
    "\n",
    "if include_neural_net == True:\n",
    "    \n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "    \n",
    "    plot_lr()\n",
    "    \n",
    "    model_2 = get_tf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:32.601270Z",
     "iopub.status.busy": "2020-09-17T01:05:32.598988Z",
     "iopub.status.idle": "2020-09-17T01:05:32.602135Z",
     "shell.execute_reply": "2020-09-17T01:05:32.602940Z"
    },
    "papermill": {
     "duration": 0.052747,
     "end_time": "2020-09-17T01:05:32.603099",
     "exception": false,
     "start_time": "2020-09-17T01:05:32.550352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Logistic Regression model\n",
    "\n",
    "if include_logreg == True:\n",
    "    \n",
    "    model_3 = MultiOutputClassifier(LogisticRegression(max_iter=10000, tol=0.1, C = 0.5,verbose=0,random_state = SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043252,
     "end_time": "2020-09-17T01:05:32.686237",
     "exception": false,
     "start_time": "2020-09-17T01:05:32.642985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:32.761230Z",
     "iopub.status.busy": "2020-09-17T01:05:32.760344Z",
     "iopub.status.idle": "2020-09-17T01:05:32.764793Z",
     "shell.execute_reply": "2020-09-17T01:05:32.764045Z"
    },
    "papermill": {
     "duration": 0.04125,
     "end_time": "2020-09-17T01:05:32.764903",
     "exception": false,
     "start_time": "2020-09-17T01:05:32.723653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "final_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:05:32.844902Z",
     "iopub.status.busy": "2020-09-17T01:05:32.837972Z",
     "iopub.status.idle": "2020-09-17T01:26:43.442646Z",
     "shell.execute_reply": "2020-09-17T01:26:43.443424Z"
    },
    "papermill": {
     "duration": 1270.645956,
     "end_time": "2020-09-17T01:26:43.443629",
     "exception": false,
     "start_time": "2020-09-17T01:05:32.797673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fold 1\n",
      "TRAIN INDEX: [    0     2     3 ... 23811 23812 23813] VALID INDEX: [    1     5     8 ... 23803 23809 23810]\n",
      "Beginning to fit  <class 'sklearn.multioutput.MultiOutputClassifier'>\n",
      "Total time taken to fit model:  205.999587059021  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.016969861136905018\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.8345 - accuracy: 0.0111 - val_loss: 0.6720 - val_accuracy: 0.0420\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.6899 - accuracy: 0.0167 - val_loss: 0.5520 - val_accuracy: 0.0198\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.0147 - val_loss: 0.2596 - val_accuracy: 0.0146\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.1674 - accuracy: 0.0171 - val_loss: 0.0834 - val_accuracy: 0.0440\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0648 - accuracy: 0.0274 - val_loss: 0.0415 - val_accuracy: 0.0576\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0369 - accuracy: 0.0389 - val_loss: 0.0289 - val_accuracy: 0.0593\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0281 - accuracy: 0.0483 - val_loss: 0.0240 - val_accuracy: 0.0721\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0243 - accuracy: 0.0550 - val_loss: 0.0222 - val_accuracy: 0.0553\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0224 - accuracy: 0.0625 - val_loss: 0.0209 - val_accuracy: 0.0821\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0217 - accuracy: 0.0697 - val_loss: 0.0205 - val_accuracy: 0.0657\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0211 - accuracy: 0.0698 - val_loss: 0.0200 - val_accuracy: 0.0895\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0207 - accuracy: 0.0767 - val_loss: 0.0198 - val_accuracy: 0.0694\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0206 - accuracy: 0.0753 - val_loss: 0.0197 - val_accuracy: 0.0899\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0205 - accuracy: 0.0786 - val_loss: 0.0196 - val_accuracy: 0.0857\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.0770 - val_loss: 0.0194 - val_accuracy: 0.0892\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.0780 - val_loss: 0.0193 - val_accuracy: 0.0904\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.0805 - val_loss: 0.0193 - val_accuracy: 0.0870\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0200 - accuracy: 0.0825 - val_loss: 0.0192 - val_accuracy: 0.0768\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0199 - accuracy: 0.0817 - val_loss: 0.0191 - val_accuracy: 0.0808\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.0821 - val_loss: 0.0191 - val_accuracy: 0.0793\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.2809781301802998e-05.\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.0815 - val_loss: 0.0190 - val_accuracy: 0.0830\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1966846911262098e-05.\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.0843 - val_loss: 0.0190 - val_accuracy: 0.0810\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.137679283788347e-05.\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.0843 - val_loss: 0.0190 - val_accuracy: 0.0761\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0963754986518429e-05.\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.0815 - val_loss: 0.0189 - val_accuracy: 0.0768\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.06746284905629e-05.\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.0816 - val_loss: 0.0189 - val_accuracy: 0.0768\n",
      "Total time taken to fit model:  25.601309776306152  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.018892503395562574\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning fold 2\n",
      "TRAIN INDEX: [    0     1     3 ... 23810 23811 23812] VALID INDEX: [    2    10    11 ... 23805 23806 23813]\n",
      "Beginning to fit  <class 'sklearn.multioutput.MultiOutputClassifier'>\n",
      "Total time taken to fit model:  203.88428163528442  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.017108951323896095\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0194 - accuracy: 0.0874 - val_loss: 0.0184 - val_accuracy: 0.0974\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0190 - accuracy: 0.0891 - val_loss: 0.0182 - val_accuracy: 0.1003\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0184 - accuracy: 0.0941 - val_loss: 0.0176 - val_accuracy: 0.0878\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0179 - accuracy: 0.0964 - val_loss: 0.0172 - val_accuracy: 0.1105\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.1024 - val_loss: 0.0169 - val_accuracy: 0.0919\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.1096 - val_loss: 0.0166 - val_accuracy: 0.0999\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.1158 - val_loss: 0.0165 - val_accuracy: 0.1139\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.1207 - val_loss: 0.0169 - val_accuracy: 0.1250\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.1243 - val_loss: 0.0161 - val_accuracy: 0.1105\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.1361 - val_loss: 0.0162 - val_accuracy: 0.1201\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.1390 - val_loss: 0.0160 - val_accuracy: 0.1332\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.1440 - val_loss: 0.0159 - val_accuracy: 0.1149\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.1448 - val_loss: 0.0159 - val_accuracy: 0.1147\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.1501 - val_loss: 0.0158 - val_accuracy: 0.1144\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0148 - accuracy: 0.1522 - val_loss: 0.0158 - val_accuracy: 0.1154\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.1536 - val_loss: 0.0158 - val_accuracy: 0.1164\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.1540 - val_loss: 0.0158 - val_accuracy: 0.1172\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.1569 - val_loss: 0.0158 - val_accuracy: 0.1181\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.1570 - val_loss: 0.0158 - val_accuracy: 0.1186\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.1595 - val_loss: 0.0158 - val_accuracy: 0.1174\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.2809781301802998e-05.\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.1600 - val_loss: 0.0158 - val_accuracy: 0.1172\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1966846911262098e-05.\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.1600 - val_loss: 0.0157 - val_accuracy: 0.1171\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.137679283788347e-05.\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.1628 - val_loss: 0.0157 - val_accuracy: 0.1182\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0963754986518429e-05.\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.1646 - val_loss: 0.0157 - val_accuracy: 0.1179\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.06746284905629e-05.\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.1647 - val_loss: 0.0157 - val_accuracy: 0.1174\n",
      "Total time taken to fit model:  22.561139583587646  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.015725811187295134\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning fold 3\n",
      "TRAIN INDEX: [    0     1     2 ... 23811 23812 23813] VALID INDEX: [    6     7    19 ... 23804 23807 23808]\n",
      "Beginning to fit  <class 'sklearn.multioutput.MultiOutputClassifier'>\n",
      "Total time taken to fit model:  203.57993364334106  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.01699485220186941\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.1458 - val_loss: 0.0134 - val_accuracy: 0.1779\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.1490 - val_loss: 0.0135 - val_accuracy: 0.1787\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.1549 - val_loss: 0.0135 - val_accuracy: 0.1685\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.1612 - val_loss: 0.0135 - val_accuracy: 0.1772\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.1722 - val_loss: 0.0136 - val_accuracy: 0.1755\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.1896 - val_loss: 0.0136 - val_accuracy: 0.1690\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.1999 - val_loss: 0.0137 - val_accuracy: 0.1594\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.2111 - val_loss: 0.0137 - val_accuracy: 0.1616\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.2459 - val_loss: 0.0137 - val_accuracy: 0.1665\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0106 - accuracy: 0.2738 - val_loss: 0.0136 - val_accuracy: 0.1643\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.2994 - val_loss: 0.0136 - val_accuracy: 0.1624\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 0.3170 - val_loss: 0.0136 - val_accuracy: 0.1626\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.3339 - val_loss: 0.0136 - val_accuracy: 0.1670\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.3427 - val_loss: 0.0136 - val_accuracy: 0.1656\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.3500 - val_loss: 0.0136 - val_accuracy: 0.1653\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.3527 - val_loss: 0.0137 - val_accuracy: 0.1655\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.3584 - val_loss: 0.0137 - val_accuracy: 0.1671\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.3622 - val_loss: 0.0137 - val_accuracy: 0.1668\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.3658 - val_loss: 0.0137 - val_accuracy: 0.1665\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.3681 - val_loss: 0.0137 - val_accuracy: 0.1675\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.2809781301802998e-05.\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.3711 - val_loss: 0.0137 - val_accuracy: 0.1676\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1966846911262098e-05.\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.3762 - val_loss: 0.0137 - val_accuracy: 0.1671\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.137679283788347e-05.\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.3751 - val_loss: 0.0137 - val_accuracy: 0.1668\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0963754986518429e-05.\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.3774 - val_loss: 0.0137 - val_accuracy: 0.1673\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.06746284905629e-05.\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.3799 - val_loss: 0.0137 - val_accuracy: 0.1675\n",
      "Total time taken to fit model:  21.7942214012146  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.013738553290465035\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning fold 4\n",
      "TRAIN INDEX: [    1     2     5 ... 23809 23810 23813] VALID INDEX: [    0     3     4 ... 23802 23811 23812]\n",
      "Beginning to fit  <class 'sklearn.multioutput.MultiOutputClassifier'>\n",
      "Total time taken to fit model:  203.6506679058075  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.016923604243595652\n",
      "Calculating final predictions...\n",
      "Done\n",
      "Beginning to fit  <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.2979 - val_loss: 0.0052 - val_accuracy: 0.4697\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00014.\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.3036 - val_loss: 0.0055 - val_accuracy: 0.4572\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00017999999999999998.\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.3187 - val_loss: 0.0058 - val_accuracy: 0.4431\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00021999999999999998.\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.3300 - val_loss: 0.0061 - val_accuracy: 0.4267\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00026.\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.3432 - val_loss: 0.0064 - val_accuracy: 0.4063\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.3577 - val_loss: 0.0070 - val_accuracy: 0.3859\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.3725 - val_loss: 0.0072 - val_accuracy: 0.3931\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.3988 - val_loss: 0.0074 - val_accuracy: 0.3571\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00021299999999999995.\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.4299 - val_loss: 0.0074 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00015209999999999996.\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.4535 - val_loss: 0.0074 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00010946999999999995.\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.4745 - val_loss: 0.0073 - val_accuracy: 0.3570\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 7.962899999999998e-05.\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.4840 - val_loss: 0.0072 - val_accuracy: 0.3586\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 5.874029999999997e-05.\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.4971 - val_loss: 0.0072 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 4.411820999999998e-05.\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0036 - accuracy: 0.5042 - val_loss: 0.0072 - val_accuracy: 0.3598\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 3.388274699999999e-05.\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.5074 - val_loss: 0.0072 - val_accuracy: 0.3613\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 2.6717922899999988e-05.\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.5097 - val_loss: 0.0072 - val_accuracy: 0.3608\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 2.1702546029999993e-05.\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.5141 - val_loss: 0.0072 - val_accuracy: 0.3627\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.8191782220999995e-05.\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.5169 - val_loss: 0.0072 - val_accuracy: 0.3628\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.5734247554699994e-05.\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.5142 - val_loss: 0.0072 - val_accuracy: 0.3654\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.4013973288289997e-05.\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.5199 - val_loss: 0.0072 - val_accuracy: 0.3645\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.2809781301802998e-05.\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.5173 - val_loss: 0.0072 - val_accuracy: 0.3639\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.1966846911262098e-05.\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.5193 - val_loss: 0.0072 - val_accuracy: 0.3632\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.137679283788347e-05.\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.5182 - val_loss: 0.0072 - val_accuracy: 0.3625\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0963754986518429e-05.\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.5197 - val_loss: 0.0072 - val_accuracy: 0.3613\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.06746284905629e-05.\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.5193 - val_loss: 0.0072 - val_accuracy: 0.3633\n",
      "Total time taken to fit model:  22.154569387435913  seconds\n",
      "Getting validation predictions...\n",
      "Validation log loss score: 0.007205899472301264\n",
      "Calculating final predictions...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Stratified K-Fold loop \n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    \n",
    "    print('Beginning fold',fold+1)\n",
    "    print(\"TRAIN INDEX:\", train_index, \"VALID INDEX:\", valid_index)\n",
    "    \n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    if include_xgboost == True:\n",
    "        \n",
    "        run_model(model_1,X_train,X_valid,y_train,y_valid) # takes ~4 minutes\n",
    "        \n",
    "    if include_neural_net == True:\n",
    "        \n",
    "        run_model(model_2,X_train,X_valid,y_train,y_valid) # takes ~10 seconds with GPU\n",
    "        \n",
    "    if include_logreg == True:\n",
    "        \n",
    "        run_model(model_3,X_train,X_valid,y_train,y_valid) # takes ~8 min\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:26:44.832459Z",
     "iopub.status.busy": "2020-09-17T01:26:44.829917Z",
     "iopub.status.idle": "2020-09-17T01:26:44.835544Z",
     "shell.execute_reply": "2020-09-17T01:26:44.835032Z"
    },
    "papermill": {
     "duration": 0.632818,
     "end_time": "2020-09-17T01:26:44.835693",
     "exception": false,
     "start_time": "2020-09-17T01:26:44.202875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation scores:  [0.016969861136905018, 0.018892503395562574, 0.017108951323896095, 0.015725811187295134, 0.01699485220186941, 0.013738553290465035, 0.016923604243595652, 0.007205899472301264]\n"
     ]
    }
   ],
   "source": [
    "### Show all CV scores\n",
    "\n",
    "print('Cross Validation scores: ',cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:26:45.979063Z",
     "iopub.status.busy": "2020-09-17T01:26:45.978160Z",
     "iopub.status.idle": "2020-09-17T01:26:46.015026Z",
     "shell.execute_reply": "2020-09-17T01:26:46.014447Z"
    },
    "papermill": {
     "duration": 0.604687,
     "end_time": "2020-09-17T01:26:46.015146",
     "exception": false,
     "start_time": "2020-09-17T01:26:45.410459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling final predictions\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Ensemble final predictions\n",
    "\n",
    "print('Ensembling final predictions')\n",
    "final_predictions = np.mean(np.array(final_preds),axis=0)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.576105,
     "end_time": "2020-09-17T01:26:47.159359",
     "exception": false,
     "start_time": "2020-09-17T01:26:46.583254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:26:48.293073Z",
     "iopub.status.busy": "2020-09-17T01:26:48.292203Z",
     "iopub.status.idle": "2020-09-17T01:26:50.848148Z",
     "shell.execute_reply": "2020-09-17T01:26:50.848691Z"
    },
    "papermill": {
     "duration": 3.125343,
     "end_time": "2020-09-17T01:26:50.848855",
     "exception": false,
     "start_time": "2020-09-17T01:26:47.723512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Output final predictions\n",
    "\n",
    "sample_sub_df.iloc[:,1:] = final_predictions\n",
    "sample_sub_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T01:26:52.003531Z",
     "iopub.status.busy": "2020-09-17T01:26:52.002863Z",
     "iopub.status.idle": "2020-09-17T01:26:52.454790Z",
     "shell.execute_reply": "2020-09-17T01:26:52.455311Z"
    },
    "papermill": {
     "duration": 1.042226,
     "end_time": "2020-09-17T01:26:52.455451",
     "exception": false,
     "start_time": "2020-09-17T01:26:51.413225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.079510</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.024040</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.078124</td>\n",
       "      <td>0.059890</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.125850</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.890881</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.679910</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.253538</td>\n",
       "      <td>0.020439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "count                  3982.000000             3982.000000     3982.000000   \n",
       "mean                      0.001545                0.001587        0.001712   \n",
       "std                       0.000517                0.000323        0.000602   \n",
       "min                       0.001003                0.000996        0.001004   \n",
       "25%                       0.001442                0.001452        0.001511   \n",
       "50%                       0.001508                0.001539        0.001613   \n",
       "75%                       0.001582                0.001662        0.001770   \n",
       "max                       0.024040                0.007506        0.012992   \n",
       "\n",
       "       acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "count                     3982.000000                        3982.000000   \n",
       "mean                         0.006909                           0.011052   \n",
       "std                          0.004228                           0.007025   \n",
       "min                          0.000828                           0.000598   \n",
       "25%                          0.005045                           0.006613   \n",
       "50%                          0.006518                           0.010261   \n",
       "75%                          0.008242                           0.014248   \n",
       "max                          0.101746                           0.081500   \n",
       "\n",
       "       acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "count                     3982.000000                 3982.000000   \n",
       "mean                         0.003181                    0.002461   \n",
       "std                          0.001408                    0.001876   \n",
       "min                          0.001001                    0.000846   \n",
       "25%                          0.002457                    0.001904   \n",
       "50%                          0.003052                    0.002212   \n",
       "75%                          0.003648                    0.002597   \n",
       "max                          0.034544                    0.057349   \n",
       "\n",
       "       adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "count                    3982.000000                 3982.000000   \n",
       "mean                        0.004512                    0.001459   \n",
       "std                         0.003599                    0.001232   \n",
       "min                         0.000719                    0.000990   \n",
       "25%                         0.003053                    0.001383   \n",
       "50%                         0.003930                    0.001428   \n",
       "75%                         0.004998                    0.001480   \n",
       "max                         0.078124                    0.059890   \n",
       "\n",
       "       adrenergic_receptor_agonist  ...  \\\n",
       "count                  3982.000000  ...   \n",
       "mean                      0.009987  ...   \n",
       "std                       0.010263  ...   \n",
       "min                       0.000690  ...   \n",
       "25%                       0.006088  ...   \n",
       "50%                       0.008694  ...   \n",
       "75%                       0.011701  ...   \n",
       "max                       0.245536  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "count                            3982.000000   3982.000000      3982.000000   \n",
       "mean                                0.001408      0.001814         0.001918   \n",
       "std                                 0.000155      0.002773         0.001053   \n",
       "min                                 0.001001      0.001000         0.000937   \n",
       "25%                                 0.001364      0.001488         0.001647   \n",
       "50%                                 0.001403      0.001590         0.001802   \n",
       "75%                                 0.001453      0.001763         0.002004   \n",
       "max                                 0.004545      0.125850         0.047447   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "count        3982.000000                3982.000000   \n",
       "mean            0.012505                   0.002727   \n",
       "std             0.079510                   0.001558   \n",
       "min             0.000861                   0.001184   \n",
       "25%             0.002085                   0.002039   \n",
       "50%             0.002689                   0.002366   \n",
       "75%             0.003720                   0.002878   \n",
       "max             0.890881                   0.028752   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor    vitamin_b  \\\n",
       "count                            3982.000000      3982.000000  3982.000000   \n",
       "mean                                0.001430         0.005926     0.001640   \n",
       "std                                 0.000157         0.026243     0.000467   \n",
       "min                                 0.001007         0.000829     0.001001   \n",
       "25%                                 0.001376         0.002027     0.001508   \n",
       "50%                                 0.001427         0.002420     0.001598   \n",
       "75%                                 0.001487         0.003366     0.001709   \n",
       "max                                 0.003765         0.679910     0.020867   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "count                 3982.000000    3982.000000  \n",
       "mean                     0.002198       0.001781  \n",
       "std                      0.008607       0.000660  \n",
       "min                      0.000851       0.001006  \n",
       "25%                      0.001558       0.001563  \n",
       "50%                      0.001734       0.001687  \n",
       "75%                      0.001965       0.001857  \n",
       "max                      0.253538       0.020439  \n",
       "\n",
       "[8 rows x 206 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Insight into final predictions\n",
    "\n",
    "sample_sub_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1307.426484,
   "end_time": "2020-09-17T01:26:54.832073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-17T01:05:07.405589",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
